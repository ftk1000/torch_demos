{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_CUDAnn_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftk1000/torch_demos/blob/master/pytorch_CUDAnn_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUq-07eWT6b5",
        "colab_type": "text"
      },
      "source": [
        "# pytorch_CUDAnn_demo.ipynb\n",
        "\n",
        " https://pytorch.org/tutorials/beginner/pytorch_with_examples.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azL77ggPTuw4",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch:nn module\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LKe2U62Fu4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import time\n",
        "assert torch.cuda.is_available()\n",
        "cuda_device = torch.device(\"cuda\")  # device object representing GPU\n",
        "\n",
        "# batch_size = 16; input_features = 32; state_size = 128\n",
        "# # Note the device=cuda_device arguments here\n",
        "# X = torch.randn(batch_size, input_features, device=cuda_device)\n",
        "# h = torch.randn(batch_size, state_size, device=cuda_device)\n",
        "# C = torch.randn(batch_size, state_size, device=cuda_device)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOniAsNvyfim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d984f17-02a7-4757-99ce-eaa7a5384f1a"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZC3HMc1Tw9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c1443be6-a0f7-43eb-8701-c54e42ce5d5d"
      },
      "source": [
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random Tensors to hold inputs and outputs\n",
        "x = torch.randn(N, D_in, device=cuda_device)\n",
        "y = torch.randn(N, D_out, device=cuda_device)\n",
        "\n",
        "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
        "# is a Module which contains other Modules, and applies them in sequence to\n",
        "# produce its output. Each Linear Module computes output from input using a\n",
        "# linear function, and holds internal Tensors for its weight and bias.\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ").to(cuda_device)\n",
        "\n",
        "# The nn package also contains definitions of popular loss functions; in this\n",
        "# case we will use Mean Squared Error (MSE) as our loss function.\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "fwd_time = bkwd_time = 0\n",
        "\n",
        "TIMELENGTH = 5000\n",
        "\n",
        "PRINT_INTERVAL = TIMELENGTH/10\n",
        "\n",
        "learning_rate = 1e-4\n",
        "for t in range(TIMELENGTH):\n",
        "    start_time = time.time()\n",
        "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "    # override the __call__ operator so you can call them like functions. When\n",
        "    # doing so you pass a Tensor of input data to the Module and it produces\n",
        "    # a Tensor of output data.\n",
        "    y_pred = model(x)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
        "    # values of y, and the loss function returns a Tensor containing the\n",
        "    # loss.\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % PRINT_INTERVAL == PRINT_INTERVAL-1:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero the gradients before running the backward pass.\n",
        "    model.zero_grad()\n",
        "    fwd_time += time.time() - start_time\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "    # parameters of the model. Internally, the parameters of each Module are stored\n",
        "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "    # all learnable parameters in the model.\n",
        "    start_time = time.time()\n",
        "    loss.backward()\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "    # we can access its gradients like we did before.\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "    bkwd_time += time.time() - start_time    \n",
        "\n",
        "print('Forward: {:.3f} us | Backward {:.3f} us'.format(fwd_time * 1e6/1e5, bkwd_time * 1e6/1e5))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "499 3.0344322112796362e-06\n",
            "999 6.336886571034483e-10\n",
            "1499 1.339501148889255e-10\n",
            "1999 6.136480906748787e-11\n",
            "2499 3.741347162633524e-11\n",
            "2999 2.4342446461322886e-11\n",
            "3499 1.864106612126104e-11\n",
            "3999 1.4826671140832914e-11\n",
            "4499 1.1493074721091734e-11\n",
            "4999 9.779886102345703e-12\n",
            "Forward: 16.387 us | Backward 28.330 us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Hc2-qkUKcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1g2p9QwFtVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}